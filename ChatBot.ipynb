{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to see internal processing steps:\n",
      "Enter you choice : no\n",
      "Start talking with the bot (type quit to stop)!\n",
      "You: how are you\n",
      "***** This seems to be kind of out of context. General response can be *****\n",
      "chatbot: Okay.\n",
      "You: how to drive car\n",
      "***** This seems to be kind of out of context. General response can be *****\n",
      "chatbot: I see.\n",
      "You: how to drive a car\n",
      "chatbot: you can toggle the key position for starting and stopping\n",
      "You: how to apply brake\n",
      "chatbot: Please read the manual\n",
      "You: will talk later\n",
      "chatbot: Good bye!\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "class Chatbot:\n",
    "\n",
    "    showWorking = False\n",
    "    train_again=False\n",
    "    vocabulary=[]\n",
    "    labels=[]\n",
    "    responseDictionary = {}\n",
    "    stemmer = PorterStemmer()\n",
    "    labelFileName= ''\n",
    "    vocabularyFileName = ''\n",
    "    responseFileName = ''\n",
    "    dataSetFileName = ''\n",
    "    feedbackFileName = ''\n",
    "    modelFileName = ''\n",
    "    \n",
    "    def __init__(self,train_again=False):\n",
    "        Chatbot.train_again = train_again\n",
    "\n",
    "    # this method gives the model depending on passed parameter like\n",
    "    # train and then gives a model or by retriving already computed model from saved file.\n",
    "    # also gives different model itself if instructed.\n",
    "    def get_model(self,isCommonTalk=0):\n",
    "        \n",
    "        if not isCommonTalk:\n",
    "            Chatbot.labelFileName= 'LabelList.json'\n",
    "            Chatbot.vocabularyFileName = 'VocabularyList.json'\n",
    "            Chatbot.responseFileName = 'responseDictionary.json'\n",
    "            Chatbot.dataSetFileName = 'CommonIntentions.json'\n",
    "            Chatbot.feedbackFileName = 'feedback.json'\n",
    "            Chatbot.modelFileName = 'chatBotContext.h5'\n",
    "        else:\n",
    "            Chatbot.labelFileName= 'LabelList_smallTalk.json'\n",
    "            Chatbot.vocabularyFileName = 'VocabularyList_smallTalk.json'\n",
    "            Chatbot.responseFileName = 'responseDictionary_smallTalk.json'\n",
    "            Chatbot.dataSetFileName = 'CommonIntentions_smallTalk.json'\n",
    "            Chatbot.feedbackFileName = 'feedback.json'\n",
    "            Chatbot.modelFileName = 'chatBot_smallTalk.h5'\n",
    "            \n",
    "        # This section retrives saved model    \n",
    "        if not Chatbot.train_again:\n",
    "            \n",
    "            \n",
    "            with open (Chatbot.labelFileName) as fl:\n",
    "                Chatbot.labels = json.load(fl)\n",
    "            \n",
    "            with open (Chatbot.vocabularyFileName) as fv:\n",
    "                Chatbot.vocabulary = json.load(fv)\n",
    "                \n",
    "            with open (Chatbot.responseFileName) as fr:\n",
    "                Chatbot.responseDictionary = json.load(fr)\n",
    "                \n",
    "            model= tf.keras.models.load_model(Chatbot.modelFileName)\n",
    "            \n",
    "        # In this section we create new model from the input intent json file and saves it for future reference.\n",
    "        else:\n",
    "            with open(Chatbot.dataSetFileName) as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            docs_x = []\n",
    "            docs_y = []\n",
    "\n",
    "            for intent in data['intents']:\n",
    "                \n",
    "                Chatbot.responseDictionary[intent['tag']] = []\n",
    "                responseList=[]\n",
    "                for response in intent['responses']:\n",
    "                    responseList.append(response)\n",
    "                \n",
    "                # saving response to response dictinary so as to get O(1) response time\n",
    "                Chatbot.responseDictionary[intent['tag']] = responseList\n",
    "                \n",
    "                for pattern in intent['patterns']:\n",
    "                    wrds = tokenize_and_get_stem(pattern)\n",
    "                    if len(wrds)>0:\n",
    "                        Chatbot.vocabulary.extend(wrds)\n",
    "                        docs_x.append(wrds)\n",
    "                        docs_y.append(intent['tag'])               \n",
    "\n",
    "                if intent['tag'] not in Chatbot.labels:\n",
    "                    # saving all possible labels(intents/tag) to label list  \n",
    "                    Chatbot.labels.append(intent['tag'])\n",
    "                    \n",
    "            with open(Chatbot.responseFileName, 'w') as fp:\n",
    "                json.dump(Chatbot.responseDictionary, fp)\n",
    "                \n",
    "            # sorting vocabulary list so that all vectors of sentence have same meaning.\n",
    "            Chatbot.vocabulary = sorted(list(set(Chatbot.vocabulary)))\n",
    "            Chatbot.labels = sorted(Chatbot.labels)\n",
    "            training = []\n",
    "            output = []\n",
    "            out_empty = [0 for _ in range(len(Chatbot.labels))]\n",
    "            \n",
    "            \n",
    "            # creating input vector for traning data\n",
    "            for x, doc in enumerate(docs_x):\n",
    "                bag = []\n",
    "\n",
    "                for w in Chatbot.vocabulary:\n",
    "                    if w in doc:\n",
    "                        bag.append(1)\n",
    "                    else:\n",
    "                        bag.append(0)\n",
    "\n",
    "                output_row = out_empty[:]\n",
    "                output_row[Chatbot.labels.index(docs_y[x])] = 1\n",
    "\n",
    "                training.append(bag)\n",
    "                output.append(output_row)\n",
    "\n",
    "            training = numpy.array(training)\n",
    "            output = numpy.array(output)\n",
    "\n",
    "\n",
    "            model = tf.keras.Sequential()\n",
    "            for layer in range(3):\n",
    "            # Adds a densely-connected layer with specified units to the model:\n",
    "                model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "                tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "            # Add a output layer with softmax as activation function:\n",
    "            model.add(tf.keras.layers.Dense(len(output[0]), activation='softmax'))\n",
    "            model.compile(optimizer='adam',loss='categorical_crossentropy',metric=['accuracy'])\n",
    "            model.fit(training, output, epochs=300)\n",
    "            \n",
    "            #saving model for future use\n",
    "            model.save(Chatbot.modelFileName)\n",
    "            \n",
    "            # saving label List and vocabulary List for future reference\n",
    "            with open(Chatbot.labelFileName, 'w') as fl:\n",
    "                json.dump(Chatbot.labels, fl)\n",
    "            with open(Chatbot.vocabularyFileName, 'w') as fv:\n",
    "                json.dump(Chatbot.vocabulary, fv)\n",
    "        return model\n",
    "\n",
    "    # this gives list of all possible ways of sayings yes.\n",
    "    def get_yes_list(self):\n",
    "        return ['yes','sure','ok','okay','for sure','sure','totally','yep','ya','yeah','yup','certainly',\n",
    "                         'definitely','of course','gladly','absolutely','indeed','yah','okk','yea']\n",
    "    \n",
    "    #this method gets called when probability of predicted tag is less than .7\n",
    "    # it takes stores input sentence and its predicted tag into file for future training\n",
    "    @staticmethod\n",
    "    def feedback_save_to_file(sentence,PredictedTag):\n",
    "        feedbackDict = {}\n",
    "        feedbackDict['input'] = sentence\n",
    "        feedbackDict['PredictedTag']=PredictedTag\n",
    "        \n",
    "        #saving the sentence in feedback file\n",
    "        with open(Chatbot.feedbackFileName, 'a+') as fv:\n",
    "                json.dump(feedbackDict, fv)\n",
    "        \n",
    "    \n",
    "    # It takes continous input from user untill he/she wants to quit.\n",
    "    def chat(self):\n",
    "        \n",
    "        print(\"Do you want to see internal processing steps:\")\n",
    "        choice = input(\"Enter you choice : \")\n",
    "        if choice.lower() in self.get_yes_list():\n",
    "            Chatbot.showWorking=True\n",
    "        print(\"Start talking with the bot (type quit to stop)!\")\n",
    "        while True:\n",
    "            model = self.get_model()\n",
    "            inp = input(\"You: \")\n",
    "            \n",
    "            #Converts the input into vector form\n",
    "            bag_of_word_rep=bag_of_words(inp)\n",
    "            \n",
    "            # calls the model to predict intent of sentence\n",
    "            results = model.predict(bag_of_word_rep)\n",
    "            results_index = numpy.argmax(results)\n",
    "            tag = Chatbot.labels[results_index]\n",
    "            \n",
    "            # getting the probability of the tag predicted.\n",
    "            Probability = results[0][results_index]\n",
    "            if Chatbot.showWorking:\n",
    "                print(\"Highest intent proability:\",Probability)\n",
    "                print(\"Intent of sentence : \",tag)\n",
    "            responses = Chatbot.responseDictionary[tag]\n",
    "            \n",
    "            #fallback when the probability is less the .7 to common talk chatbot model\n",
    "            if Probability < .7:\n",
    "                Chatbot.feedback_save_to_file(inp,tag)\n",
    "                print('***** This seems to be kind of out of context. General response can be *****')\n",
    "                model = self.get_model(1)\n",
    "                bag_of_word_rep=bag_of_words(inp)\n",
    "                results = model.predict(bag_of_word_rep)\n",
    "                results_index = numpy.argmax(results)\n",
    "                tag = Chatbot.labels[results_index]\n",
    "                Probability = results[0][results_index]\n",
    "                if Chatbot.showWorking:\n",
    "                    print(\"Highest intent proability:\",Probability)\n",
    "                    print(\"Intent of sentence : \",tag)\n",
    "                responses = Chatbot.responseDictionary[tag]\n",
    "                \n",
    "                \n",
    "            print(\"chatbot:\",random.choice(responses))\n",
    "            if tag == \"quit\":\n",
    "                break\n",
    "            \n",
    "# this method gives tokens after stemming them            \n",
    "def tokenize_and_get_stem(sentence):\n",
    "        s_words = nltk.word_tokenize(sentence)\n",
    "        s_words = [Chatbot.stemmer.stem(word.lower()) for word in s_words]\n",
    "        if Chatbot.showWorking:\n",
    "            print('Stems present in sentence are:',s_words)\n",
    "        return s_words\n",
    "\n",
    "# this method takes the sentence and convert it into vector form\n",
    "def bag_of_words(sentence):\n",
    "    bags = []\n",
    "    \n",
    "    #creating hot vector\n",
    "    bag = [0 for _ in range(len(Chatbot.vocabulary))] \n",
    "    s_words = tokenize_and_get_stem(sentence)\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(Chatbot.vocabulary):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "                \n",
    "    if Chatbot.showWorking:\n",
    "        print('Vector Representation of input sentence :',bag)\n",
    "            \n",
    "    bags.append(bag)\n",
    "    bags = numpy.array(bags)\n",
    "    return bags\n",
    "        \n",
    "def main():\n",
    "    chatbot = Chatbot(False)\n",
    "    chatbot.chat()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
